\begin{abstract}
Real time and cost-effective analytics for ``Big Data''
is now a key ingredient for success in many businesses, scientific
research and engineering disciplines, and government endeavors.
The Apache Spark platform which consists of an extensible
MapReduce execution engine, pluggable resilient distributed storage
engines, and a range of procedural to declarative interfaces is
a mainstream choice for big data analytics. Unfortunately, the most
beginner of big data analytics like software engineer, computational
scientists, systems researchers, and business analysts lack
the expertise to configure the big data analytics system setting
to get good performance. Due to each of them has hundreds
of parameters for tuning. However, it is challenging to automatically
identify the best configuration for a diversity of
applications. In generally, Sparks performance out of the box
leaves much to be desired, leading to suboptimal use of resources,
time, and money (in pay as-you-go clouds platform, like AWS,
Azure etc.). We introduce Hummingbird: a novel approach to
finding the optimal configuration for big data analytics. It builds
on Spark while adapting to user needs and system workloads
to provide good performance, help users to understand and
manipulate the many tuning knobs in Spark. Furthermore,
experimental results show the Hummingbird can get the best
configuration considering the running time and computational
efficiency. Finally, the experimental results also show that the
performance can get average 28\% gain with the Hummingbird
compared with the default configuration of Spark. Certainly,
Hummingbird can also be applied to other mainstream big data
analytics systems.

\end{abstract}
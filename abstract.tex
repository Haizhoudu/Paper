\begin{abstract}
Real time and cost-effective analytics for ``Big Data'' is now a key ingredient for success in many businesses, scientific research and engineering disciplines, and government endeavors. Unfortunately, the most beginner of big data analytics like software engineer, computational scientists, systems researchers, and business analysts lack the expertise to configure the big data analytics system setting to get good performance. Due to each of big data analytics platforms has hundreds of parameters for tuning. However, it is challenging to automatically identify the best configuration for a diversity of applications. The Apache Spark platform which consists of an extensible MapReduce execution engine, pluggable resilient distributed storage engines, and a range of procedural to declarative interfaces is a mainstream choice for big data analytics. In generally, Spark performance out of the box leaves much to be desired, leading to suboptimal use of resources, time, and money (in pay as-you-go clouds platform, like AWS, Azure etc.). We introduce the Hummingbird: a novel approach to find the optimal configuration for big data analytics. It builds on Apache Spark while adapting to user needs and job workloads to provide good performance, help users to understand and manipulate the many tuning knobs in Spark. Furthermore, experimental results show the Hummingbird can get the best configuration considering running time and computational efficiency. Finally, the experimental results also show that the performance can get average 23\% gain with the Hummingbird compared with the default configuration of Spark. Certainly, Hummingbird can also be applied to other mainstream big data analytics systems.

\end{abstract}
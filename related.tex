\section{Related Work}\label{sec:related}
\par Performance optimization of big data system has been one of the hot topic in academic research areas recently due to the wide application of big data analytic platforms. But most of research works are still based on the MapReduce computing framework or Hadoop platform. Starfish \cite{starfish} uses cost-based modeling and simulation to search the desired job configurations for MapReduce workloads. AROMA \cite{AROMA} automates job configuration and resource allocation through leveraging a two phase machine learning and optimization framework for heterogeneous clouds. In reference \cite{zaharia2008Improving}, the authors point out that Hadoop's scheduler can cause severe performance degradation in heterogeneous environments and present a new scheduler called Longest Approximate Time to End. Reference \cite{kambatla2009towards} focused on analyzing the variant effect of resource consumption of different settings for the Map and Reduce slots. In reference \cite{wu2013selftuning}, the authors address these problems by presenting the Profiling and Performance Analysis-based System (PPABS) framework, which can automate the tuning of Hadoop configuration settings based on deduced application performance requirements. The key contributions includes the modifications to the well-known KMeans++ clustering and Simulated Annealing algorithms, which were required to adapt them to the MapReduce paradigm. Reference \cite{zhang2015finding} proposes to alleviate this issue with an engine that recommends configurations for a newly submitted analytics job in an intelligent and timely manner. The engine is rooted in a modified k-nearest neighbor algorithm, which finds desirable configurations from similar past jobs that have performed well. Another work \cite{firebirdHeS16} proposed a new approach of task scheduling for spark using SDN, but it can not handle the tuning of configration.

\par  The research work about the performance optimization of Apache Spark platform is still relatively few. In reference \cite{wang2015High}, the authors present simulation driven prediction model that can predict job performance with high accuracy for Apache Spark platform. Their model is used to predict the execution time and memory usage of Spark applications in the default parameter case. However, their model is too simple to predict the execution time of different configuration parameters. Ernest \cite{Ernest194946} introduce a efficient performance prediction method for  large-scale analytics, but this method can not tune any of complex parameters. The latest reference Cherrypick \cite{cherrypick2015} proposed a novel architecture for adaptively unearthing the best cloud configuration, However it just can keep a trade-off between cloud cost and Spark configration. Another work \cite{yigitbase2013towards}, the authors show that support vector regression model (SVR) has good accuracy and is also computationally efficient. Their findings reveal that their autotuning approach can provide comparable or in some cases better performance improvements than Starfish with a smaller number of parameters.

Next we will briefly introduce the Spark platform and its running modal. 
\section{Related Work}
\par Performance optimization of big data System has been one of the hot research areas in recent years due to the wide adoption of big data analytic platforms. But most of research works are based on the MapReduce computing framework or Hadoop platform. Starfish [5] uses cost-based modeling and simulation to search the desired job configurations for MapReduce workloads. AROMA [6] automates job configuration and resource allocation through leveraging a two phase machine learning and optimization framework for heterogeneous clouds. In reference [7], the authors point out that Hadoop's scheduler can cause severe performance
degradation in heterogeneous environments and present a new scheduler called Longest Approximate Time to End. Another work [8] focused on analyzing the variant effect of resource consumption of different settings for the Map and Reduce slots. In reference [9], the authors address these problems by presenting the Profiling and Performance Analysis-based System (PPABS) framework, which can automate the tuning of Hadoop configuration settings based on deduced application performance requirements. The key contributions includes the modifications to the well-known KMeans++ clustering and Simulated Annealing algorithms, which were required to adapt them to the MapReduce paradigm. Reference [10] proposes to alleviate this issue with an engine that recommends configurations for a newly submitted analytics job in an intelligent and timely manner. The engine is rooted in a modified k-nearest neighbor algorithm, which finds desirable configurations from similar past jobs that have performed well.

\par  The research work about the performance optimization of Apache Spark platform is still relatively few. In reference [11], the authors present simulation driven prediction model that can predict job performance with high accuracy for Apache Spark platform. Their model is used to predict the execution time and memory usage of Spark applications in the default parameter case. However, their model is too simple to
predict the execution time of different configuration parameters. In reference [12], the authors show that support vector regression model (SVR) has good accuracy and is also computationally efficient. Their findings reveal that their autotuning approach can provide comparable or in some cases better performance improvements than Starfish with a smaller number of parameters.
